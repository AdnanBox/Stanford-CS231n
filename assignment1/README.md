In this assignment you will practice writing backpropagation code, and training Neural Networks and Convolutional Neural Networks. The goals of this assignment are as follows:

\

- understand **Neural Networks** and how they are arranged in layered architectures

- understand and be able to implement (vectorized) **backpropagation**

- implement various **update rules** used to optimize Neural Networks

- implement **Batch Normalization** and **Layer Normalization** for training deep networks

- implement **Dropout** to regularize networks

- understand the architecture of **Convolutional Neural Networks** and get practice with training these models on data

- gain experience with a major deep learning framework, such as **TensorFlow** or **PyTorch**.

\
\
\

* ## Q1. k-Nearest Neighbour Classifier

The IPython Notebook **knn.ipynb** will walk you through implementing the kNN classifier.


* ## Q2. Training a Support Vector Machine

The IPython Notebook **svm.ipynb** will walk you through implementing the SVM classifier.


* ## Q3. Implement a Softmax Classifier

The IPython Notebook **softmax.ipynb** will walk you through implementing the Softmax classifier.


* ## Q4. Two-Layer Neural Network

The IPython Notebook **two_layer_net.ipynb** will walk you through the implementation of a two-layer neural network 
classifier.


* ## Q5. Higher Level Representation: Image Features

The IPython Notebook **features.ipynb** will walk you through this exercise, in which you will examine the improvements gained by using higher-level representations as opposed to using raw pixel values.

\
\
\
\

**NOTE:** Details about this assignment can be found [on the course webpage](https://cs231n.github.io/assignments2019/assignment1/).


In this assignment you will practice writing backpropagation code, and training Neural Networks and Convolutional Neural Networks. The goals of this assignment are as follows:
- understand **Neural Networks** and how they are arranged in layered architectures
- understand and be able to implement (vectorized) **backpropagation**
- implement various **update rules** used to optimize Neural Networks
- implement **Batch Normalization** and **Layer Normalization** for training deep networks
- implement **Dropout** to regularize networks
- understand the architecture of **Convolutional Neural Networks** and get practice with training these models on data
- gain experience with a major deep learning framework, such as **TensorFlow** or **PyTorch**.
{bl}
{bl}
{bl}
* ## Q1. k-Nearest Neighbour Classifier
The IPython Notebook **knn.ipynb** will walk you through implementing the kNN classifier.
{bl}
* ## Q2. Training a Support Vector Machine
{bl}
The IPython Notebook **svm.ipynb** will walk you through implementing the SVM classifier.
{bl}
* ## Q3. Implement a Softmax Classifier
The IPython Notebook **softmax.ipynb** will walk you through implementing the Softmax classifier.
{bl}
* ## Q4. Two-Layer Neural Network
The IPython Notebook **two_layer_net.ipynb** will walk you through the implementation of a two-layer neural network 
classifier.
{bl}
* ## Q5. Higher Level Representation: Image Features
The IPython Notebook **features.ipynb** will walk you through this exercise, in which you will examine the improvements gained by using higher-level representations as opposed to using raw pixel values.
{bl}
{bl}
{bl}
{bl}
**NOTE:** Details about this assignment can be found [on the course webpage](https://cs231n.github.io/assignments2019/assignment1/).

